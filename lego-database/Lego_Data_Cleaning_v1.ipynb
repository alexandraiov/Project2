{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "364\n"
     ]
    }
   ],
   "source": [
    "##LEGO DATA DENORMALIZATION - RACHAEL BURNS\n",
    "import csv\n",
    "\n",
    "with open(\"inventory_parts.csv\", \"rt\") as inventory_parts:\n",
    "    reader = csv.DictReader(inventory_parts)\n",
    "    headers = reader.fieldnames\n",
    "    ivty = {}\n",
    "    i=-1\n",
    "    for header in headers:\n",
    "        ivty[header]={}\n",
    "    for row in reader:\n",
    "        i+=1\n",
    "        for header in headers:\n",
    "            ivty[header][i]=row[header]  \n",
    "        \n",
    "    most = i+1\n",
    "    \n",
    "key_list = [item for item in ivty[\"color_id\"].keys()]\n",
    "print(key_list[0:5])\n",
    "#print([header + \" \" + str(type(ivty[header]))+str(len(ivty[header])) for header in headers])\n",
    "\n",
    "with open(\"colors.csv\", \"rt\") as colors:\n",
    "    reader = csv.DictReader(colors)\n",
    "    headers = {\"color_name\":\"name\", \"color_rgb\":\"rgb\", \"color_istrans\":\"is_trans\"}\n",
    "    color_data = {}\n",
    "    for header in headers.keys():\n",
    "        ivty[header] = {}\n",
    "    for row in reader:\n",
    "        color_data[int(row[\"id\"])]=row\n",
    "    for header in headers.keys():\n",
    "        for i in range(0,most):\n",
    "            ivty[header][i] = color_data[int(ivty[\"color_id\"][i])][headers[header]]\n",
    "\n",
    "#print([key + \" \" + ivty[key][i] for key in ivty.keys() for i in range(0,5)])\n",
    "\n",
    "\n",
    "with open(\"inventories.csv\") as parts:\n",
    "    reader = csv.DictReader(parts)\n",
    "    headers = {\"ivty_version\":\"version\", \"set_num\":\"set_num\"}\n",
    "    ivty_data = {}\n",
    "    for header in headers.keys():\n",
    "        ivty[header] = {}\n",
    "    for row in reader:\n",
    "        ivty_data[row[\"id\"]]=row\n",
    "    for header in headers.keys():\n",
    "        for i in range(0,most):\n",
    "            ivty[header][i] = ivty_data[ivty[\"inventory_id\"][i]][headers[header]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(\"parts.csv\") as parts:\n",
    "    count_exception = 0\n",
    "    reader = csv.DictReader(parts)\n",
    "    headers = {\"part_name\":\"name\", \"part_cat_id\":\"part_cat_id\"}\n",
    "    part_data = {}\n",
    "    for header in headers.keys():\n",
    "        ivty[header] = {}\n",
    "    for row in reader:\n",
    "        part_data[row[\"part_num\"]]=row\n",
    "    for header in headers.keys():\n",
    "        for i in range(0,most):\n",
    "            try:\n",
    "                ivty[header][i] = part_data[ivty[\"part_num\"][i]][headers[header]]\n",
    "            except:\n",
    "                #***NOTE- 364 keys do not match - ex/ 48002 in inventory parts table corresponds to \n",
    "                #48002a, 480002b in inventory table. This is bad DB design!\n",
    "                #Need to implement some kind of regexp match - placeholder for now. \n",
    "                pattern = re.compile(ivty[\"part_num\"][i] + \"[a-z]?\")\n",
    "                match_name = \"\"\n",
    "                for key in part_data.keys():\n",
    "                    if pattern.match(key):\n",
    "                        if match_name:\n",
    "                            match_name += \" / \" \n",
    "                        match_name += part_data[key][\"name\"] \n",
    "                        ivty[\"part_cat_id\"][i] = part_data[key][\"part_cat_id\"]\n",
    "                ivty[\"part_name\"][i] = match_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print([ivty[key].keys() for key in ivty.keys()])\n",
    "#print([key + \" \" + ivty[key][i] for key in ivty.keys() for i in range(0, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501882\n"
     ]
    }
   ],
   "source": [
    "with open(\"inventory_sets.csv\") as ivty_sets:\n",
    "    reader = csv.DictReader(ivty_sets)\n",
    "    headers = {\"set_quantity\":\"quantity\"}\n",
    "    ivty_set_data = {}\n",
    "    count_excp=0\n",
    "    for header in headers.keys():\n",
    "        ivty[header] = {}\n",
    "    for row in reader:\n",
    "        ivty_set_data[row[\"set_num\"]]=row\n",
    "    for header in headers.keys():\n",
    "        for i in range(0,most):\n",
    "            try:\n",
    "                ivty[header][i] = ivty_set_data[ivty[\"set_num\"][i]][headers[header]]\n",
    "            except:\n",
    "                #***NOTE: most sets are not in the inventory_sets table, so not all rows will\n",
    "                #have a quantity - for this reason and also because there's not a clear definition of\n",
    "                #either \"inventory\" or \"quantity\" I would recommend disregarding the quanity column.\n",
    "                count_excp+=1\n",
    "                \n",
    "print(count_excp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOTE: DO NOT RUN AGAIN! Will overwrite file with empty rows. \n",
    "#NOTE: Source file for sets has non-ascii characters that raise an error when trying to read as csv.\n",
    "\n",
    "with open('sets.csv', 'rb') as file:\n",
    "    with open('sets_out.csv', 'wt') as file2:\n",
    "        for row in file:\n",
    "            for char in row:\n",
    "                if char<=128:\n",
    "                    try:\n",
    "                        file2.write(chr(char))\n",
    "                    except:\n",
    "                        pass\n",
    "#This script creates a blank row between each row, I removed in excel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2796\n"
     ]
    }
   ],
   "source": [
    "with open(\"sets_out.csv\", 'rt') as sets:\n",
    "    reader = csv.DictReader(sets) \n",
    "    headers = {\"set_name\":\"name\", \"year\":\"year\", \"theme_id\":\"theme_id\", \"set_parts_count\":\"num_parts\"}\n",
    "    set_data = {}\n",
    "    count_excp=0\n",
    "    excp_list = []\n",
    "    for header in headers.keys():\n",
    "        ivty[header] = {}\n",
    "    for row in reader:\n",
    "        set_data[row[\"set_num\"]]=row\n",
    "    for header in headers.keys():\n",
    "        for i in range(0,most):\n",
    "            try:\n",
    "                ivty[header][i] = set_data[ivty[\"set_num\"][i]][headers[header]]\n",
    "            except Exception as e:\n",
    "                #if e not in excp_list:\n",
    "                #    excp_list.append(e)\n",
    "                count_excp+=1\n",
    "print(count_excp)\n",
    "\n",
    "#***NOTE - not all set ids in inventory file are in the sets file This is only 2796 instances There\n",
    "#does not seem to be a pattern as there was with the part names. This file also has the year, which \n",
    "#is important to many of our questions - \n",
    "#it makes sense to disregard the rows that do not have a year populated for that part of the analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1398\n",
      "699\n",
      "699\n",
      "107\n",
      "\n",
      "Row , Num Populated\n",
      "inventory_id , 580251\n",
      "part_num , 580251\n",
      "color_id , 580251\n",
      "quantity , 580251\n",
      "is_spare , 580251\n",
      "color_name , 580251\n",
      "color_rgb , 580251\n",
      "color_istrans , 580251\n",
      "part_name , 580251\n",
      "part_cat_id , 580144\n",
      "ivty_version , 580251\n",
      "set_num , 580251\n",
      "set_quantity , 78369\n",
      "set_name , 579552\n",
      "year , 579552\n",
      "theme_id , 579552\n",
      "set_parts_count , 579552\n",
      "theme_name , 579552\n",
      "theme_parent_id , 579552\n",
      "parent_name , 371970\n",
      "part_cat_name , 580144\n"
     ]
    }
   ],
   "source": [
    "with open(\"themes.csv\", 'rt') as themes:\n",
    "    reader = csv.DictReader(themes) \n",
    "    headers = {\"theme_name\":\"name\", \"theme_parent_id\": \"parent_id\"}\n",
    "    theme_data = {}\n",
    "    count_excp=0\n",
    "    excp_list = []\n",
    "    for header in headers.keys():\n",
    "        ivty[header] = {}\n",
    "    for row in reader:\n",
    "        theme_data[row[\"id\"]]=row\n",
    "    for header in headers.keys():\n",
    "        for i in range(0,most):\n",
    "            try:\n",
    "                ivty[header][i] = theme_data[ivty[\"theme_id\"][i]][headers[header]]\n",
    "            except Exception as e:\n",
    "                #**NOTE: of the exceptions, 699 are no theme id and 699 are theme id not in theme table.\n",
    "                excp_list.append(e)\n",
    "                count_excp+=1\n",
    "    ivty[\"parent_name\"] = {}\n",
    "    for key in ivty[\"theme_parent_id\"].keys():\n",
    "        try:\n",
    "            ivty[\"parent_name\"][key] = theme_data[ivty[\"theme_parent_id\"][key]][\"name\"]\n",
    "            #**NOTE: Next two lines check if a parent theme has another parent - some do, do we want to \n",
    "            #capture that in our data?\n",
    "            #if len(theme_data[ivty[\"theme_parent_id\"][key]][\"parent_id\"])>0:\n",
    "            #    print(theme_data[ivty[\"theme_parent_id\"][key]][\"parent_id\"])\n",
    "        except:\n",
    "            #exceptions are themes that do not have a parent, which is fine.\n",
    "            pass\n",
    "print(count_excp)\n",
    "#print(excp_list)\n",
    "#print([key + \" \" + ivty[key][i] for key in ivty.keys() for i in range(0, 10) if i in ivty[key].keys()])\n",
    "print(580251-579552)\n",
    "print(1398-699)\n",
    "\n",
    "with open(\"part_categories.csv\", 'rt') as part_cats:\n",
    "    reader = csv.DictReader(part_cats) \n",
    "    headers = {\"part_cat_name\":\"name\"}\n",
    "    part_cat_data = {}\n",
    "    count_excp=0\n",
    "    excp_list = []\n",
    "    for header in headers.keys():\n",
    "        ivty[header] = {}\n",
    "    for row in reader:\n",
    "        set_data[row[\"id\"]]=row\n",
    "    for header in headers.keys():\n",
    "        for i in range(0,most):\n",
    "            try:\n",
    "                ivty[header][i] = set_data[ivty[\"part_cat_id\"][i]][headers[header]]\n",
    "            except Exception as e:\n",
    "                #182 parts are not in a category.\n",
    "                if e not in excp_list:\n",
    "                    excp_list.append(e)\n",
    "                count_excp+=1\n",
    "print(count_excp)\n",
    "#print(excp_list)\n",
    "\n",
    "print(\"\\nRow , Num Populated\")\n",
    "for key in ivty.keys():\n",
    "        print(key, \",\", len(ivty[key].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "with open(\"lego_out.csv\", 'wt') as out:\n",
    "    writer = csv.DictWriter(out, ivty.keys(), dialect = 'excel', lineterminator = \"\\n\")\n",
    "    writer.writeheader()\n",
    "    for i in range(0, 580251):\n",
    "        row = {}\n",
    "        for key in ivty.keys():\n",
    "            try:\n",
    "                row[key] = ivty[key][i]\n",
    "            except: \n",
    "                row[key] = \"\"\n",
    "        writer.writerow(row)\n",
    "        \n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is probably a more compact and higher-performance way to implement these joins - eg. I know some python packages mimic SQL joins. However doing it from scratch was a good exercise because it made visible the inconsistencies in the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
